# ğŸ”¬ Plan de ImplementaciÃ³n: ImgRec - Sistema de Autoenfoque Inteligente

**Documento creado:** 2025-12-12  
**Ãšltima actualizaciÃ³n:** 2025-12-12  
**VersiÃ³n:** 1.0  
**Autor:** Sistema de Control L206 + C-Focus Piezo  
**Estado:** ğŸ“‹ EN PLANIFICACIÃ“N

---

## ğŸ“‹ Resumen Ejecutivo

### Objetivo Principal
Implementar un sistema de **autoenfoque inteligente** que utilice la cÃ¡mara Thorlabs con el sistema mÃ³vil XY, aplicando el modelo **U2-Net** para detectar objetos salientes (granos de polen) y realizar autoenfoque individual mediante el piezo **C-Focus**, registrando imÃ¡genes de alta calidad para cada objeto detectado.

### Objetivos Secundarios
1. **Arquitectura eficiente:** Carga Ãºnica del modelo U2-Net al inicio
2. **VisualizaciÃ³n fluida:** Vista de cÃ¡mara en tiempo real sin bloqueos
3. **Overlays informativos:** Mapas de saliencia y scores en vivo
4. **Desacoplamiento:** SeparaciÃ³n clara entre UI, lÃ³gica y hardware

---

## ğŸ” AnÃ¡lisis del Estado Actual

### âœ… Componentes Existentes

| Componente | UbicaciÃ³n | Estado | Problema |
|------------|-----------|--------|----------|
| `SmartFocusScorer` | `core/autofocus/smart_focus_scorer.py` | âš ï¸ Parcial | U2-Net no carga, usa fallback |
| `MultiObjectAutofocusController` | `core/autofocus/multi_object_autofocus.py` | âš ï¸ Parcial | Bloqueante, sin visualizaciÃ³n |
| `CFocusController` | `hardware/cfocus/cfocus_controller.py` | âœ… Funcional | - |
| `CameraWorker` | `hardware/camera/camera_worker.py` | âœ… Funcional | - |
| `CameraTab` | `gui/tabs/camera_tab.py` | âš ï¸ Sobrecargada | Demasiadas responsabilidades |
| `ImgAnalysisTab` | `gui/tabs/img_analysis_tab.py` | âœ… Funcional | Separada, no integrada |

### âŒ Problemas CrÃ­ticos Identificados

#### 1. **Modelo U2-Net NO se carga**
```python
# smart_focus_scorer.py - LÃ­nea 61-80
def load_model(self):
    if self.model is not None:
        return
    # ... cÃ³digo que NUNCA ejecuta carga real
    logger.info(f"[SmartFocusScorer] Modelo U2-Net cargado: {self.model_name}")
    # â†‘ FALSO: Solo imprime mensaje, no carga modelo
```

**Consecuencia:** Sistema usa detecciÃ³n por contornos (fallback), no U2-Net.

#### 2. **Acoplamiento excesivo CameraTab â†” MainWindow**
```python
# camera_tab.py - LÃ­nea 1211
def _connect_cfocus(self):
    if self.parent_gui:
        success = self.parent_gui.connect_cfocus()  # â† Dependencia directa
```

**Consecuencia:** CÃ³digo difÃ­cil de mantener y probar.

#### 3. **Autofoco bloqueante**
```python
# multi_object_autofocus.py - LÃ­nea 159-220
# Z-scanning ejecuta en thread principal
# UI se congela durante ~2 segundos por objeto
```

**Consecuencia:** Usuario no ve progreso, no puede cancelar.

#### 4. **Sin visualizaciÃ³n de saliencia en tiempo real**
- No hay overlay de mapas de probabilidad
- No se muestra ROI durante autofoco
- No hay indicador de score S en vivo

---

## ğŸ¯ Arquitectura Propuesta

### Diagrama de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CAPA DE PRESENTACIÃ“N                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   CameraTab     â”‚    â”‚  AutofocusPanel â”‚    â”‚  SaliencyView   â”‚     â”‚
â”‚  â”‚  (Vista Live)   â”‚    â”‚  (Controles AF) â”‚    â”‚  (Overlays)     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚           â”‚                      â”‚                      â”‚               â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                  â”‚                                      â”‚
â”‚                          [SeÃ±ales PyQt]                                 â”‚
â”‚                                  â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CAPA DE SERVICIOS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                  â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚                    MicroscopyService                          â”‚     â”‚
â”‚  â”‚  - Coordina flujo de microscopÃ­a                              â”‚     â”‚
â”‚  â”‚  - Gestiona estados (IDLE, MOVING, DETECTING, FOCUSING)       â”‚     â”‚
â”‚  â”‚  - Emite seÃ±ales de progreso                                  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                  â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ DetectionServiceâ”‚    â”‚ AutofocusServiceâ”‚    â”‚ CaptureService  â”‚     â”‚
â”‚  â”‚ (U2-Net)        â”‚    â”‚ (Z-Scanning)    â”‚    â”‚ (Guardar imgs)  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚           â”‚                      â”‚                      â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                      â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           â”‚              CAPA DE HARDWARE               â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           â”‚                      â”‚                      â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  CameraWorker   â”‚    â”‚ CFocusControllerâ”‚    â”‚  MotorControl  â”‚      â”‚
â”‚  â”‚  (Thorlabs)     â”‚    â”‚  (Mad City Labs)â”‚    â”‚  (Arduino XY)  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Principios de DiseÃ±o

1. **Carga Ãºnica de U2-Net:** Singleton en `DetectionService`
2. **Procesamiento asÃ­ncrono:** Workers en threads separados
3. **ComunicaciÃ³n por seÃ±ales:** Sin llamadas directas entre capas
4. **VisualizaciÃ³n no-bloqueante:** Overlays en thread de renderizado

---

## ğŸ“¦ MÃ³dulos a Implementar/Refactorizar

### FASE 1: Carga Correcta de U2-Net (CRÃTICO)

**Archivo:** `src/core/detection/u2net_detector.py` (NUEVO)

```python
class U2NetDetector:
    """
    Singleton para detecciÃ³n de objetos salientes con U2-Net.
    Carga el modelo UNA SOLA VEZ al inicio.
    """
    _instance = None
    _model = None
    _device = None
    
    @classmethod
    def get_instance(cls):
        if cls._instance is None:
            cls._instance = cls()
            cls._load_model()
        return cls._instance
    
    @classmethod
    def _load_model(cls):
        """Carga U2-Net (u2netp para velocidad)."""
        import torch
        from models.u2net.model_def import U2NETP
        
        cls._device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        cls._model = U2NETP(3, 1)
        
        # Cargar pesos pre-entrenados
        weights_path = "models/u2net/u2netp.pth"
        cls._model.load_state_dict(torch.load(weights_path, map_location=cls._device))
        cls._model.to(cls._device)
        cls._model.eval()
        
        logger.info(f"[U2NetDetector] Modelo cargado en {cls._device}")
    
    def detect(self, image: np.ndarray) -> Tuple[np.ndarray, List[Dict]]:
        """
        Detecta objetos salientes.
        
        Returns:
            saliency_map: Mapa de probabilidades [0-1]
            objects: Lista de {bbox, area, probability, centroid}
        """
        # Preprocesar
        input_tensor = self._preprocess(image)
        
        # Inferencia
        with torch.no_grad():
            d1, *_ = self._model(input_tensor)
            saliency = torch.sigmoid(d1).squeeze().cpu().numpy()
        
        # Post-procesar: extraer objetos
        objects = self._extract_objects(saliency)
        
        return saliency, objects
```

**Tareas:**
- [ ] Crear archivo `u2net_detector.py`
- [ ] Implementar patrÃ³n Singleton
- [ ] Descargar pesos `u2netp.pth` (~4MB)
- [ ] Verificar carga en GPU/CPU
- [ ] Test unitario de detecciÃ³n

---

### FASE 2: Servicio de DetecciÃ³n AsÃ­ncrono

**Archivo:** `src/core/services/detection_service.py` (NUEVO)

```python
class DetectionWorker(QThread):
    """Worker para detecciÃ³n en background."""
    
    detection_complete = pyqtSignal(np.ndarray, list)  # saliency_map, objects
    progress_updated = pyqtSignal(str)  # mensaje de estado
    
    def __init__(self, detector: U2NetDetector):
        super().__init__()
        self.detector = detector
        self.frame_queue = Queue(maxsize=1)
        self.running = False
    
    def submit_frame(self, frame: np.ndarray):
        """EnvÃ­a frame para detecciÃ³n (no bloqueante)."""
        try:
            self.frame_queue.put_nowait(frame)
        except Full:
            pass  # Descartar si hay frame pendiente
    
    def run(self):
        self.running = True
        while self.running:
            try:
                frame = self.frame_queue.get(timeout=0.1)
                saliency, objects = self.detector.detect(frame)
                self.detection_complete.emit(saliency, objects)
            except Empty:
                continue
```

**Tareas:**
- [ ] Crear `detection_service.py`
- [ ] Implementar cola de frames
- [ ] SeÃ±ales para resultados
- [ ] Manejo de cancelaciÃ³n

---

### FASE 3: Servicio de Autofoco AsÃ­ncrono

**Archivo:** `src/core/services/autofocus_service.py` (NUEVO)

```python
class AutofocusWorker(QThread):
    """Worker para Z-scanning en background."""
    
    # SeÃ±ales para UI
    z_position_changed = pyqtSignal(float, float)  # z_current, score
    scan_progress = pyqtSignal(int, int)  # current_step, total_steps
    focus_found = pyqtSignal(float, float, np.ndarray)  # z_optimal, score, focused_frame
    scan_complete = pyqtSignal(list)  # lista de FocusedCapture
    
    def __init__(self, cfocus: CFocusController, camera_callback):
        super().__init__()
        self.cfocus = cfocus
        self.get_frame = camera_callback
        self.objects_to_focus = []
        self.running = False
    
    def start_scan(self, objects: List[DetectedObject], config: dict):
        """Inicia Z-scanning para lista de objetos."""
        self.objects_to_focus = objects
        self.config = config
        self.start()
    
    def run(self):
        self.running = True
        captures = []
        
        for obj in self.objects_to_focus:
            if not self.running:
                break
            
            z_opt, score, frame = self._scan_single_object(obj)
            captures.append(FocusedCapture(obj, z_opt, score, frame))
        
        self.scan_complete.emit(captures)
    
    def _scan_single_object(self, obj: DetectedObject) -> Tuple[float, float, np.ndarray]:
        """Z-scanning para un objeto con emisiÃ³n de progreso."""
        z_range = self.cfocus.get_z_range()
        z_step = self.config.get('z_step', 5.0)
        
        z_positions = np.arange(0, z_range, z_step)
        scores = []
        
        for i, z in enumerate(z_positions):
            if not self.running:
                break
            
            self.cfocus.move_z(z)
            time.sleep(0.05)  # Settle
            
            frame = self.get_frame()
            score = self._calculate_sharpness(frame, obj.bounding_box)
            scores.append(score)
            
            # Emitir progreso para UI
            self.z_position_changed.emit(z, score)
            self.scan_progress.emit(i + 1, len(z_positions))
        
        # Encontrar Ã³ptimo
        best_idx = np.argmax(scores)
        z_optimal = z_positions[best_idx]
        
        # Mover a posiciÃ³n Ã³ptima y capturar
        self.cfocus.move_z(z_optimal)
        time.sleep(0.05)
        final_frame = self.get_frame()
        final_score = scores[best_idx]
        
        self.focus_found.emit(z_optimal, final_score, final_frame)
        
        return z_optimal, final_score, final_frame
```

**Tareas:**
- [ ] Crear `autofocus_service.py`
- [ ] Implementar seÃ±ales de progreso
- [ ] Permitir cancelaciÃ³n mid-scan
- [ ] Emitir frames para visualizaciÃ³n

---

### FASE 4: Panel de VisualizaciÃ³n con Overlays

**Archivo:** `src/gui/widgets/saliency_overlay.py` (NUEVO)

```python
class SaliencyOverlayWidget(QWidget):
    """
    Widget que superpone informaciÃ³n de detecciÃ³n sobre la imagen de cÃ¡mara.
    
    Muestra:
    - Mapa de saliencia (semi-transparente)
    - Bounding boxes de objetos detectados
    - Scores de cada objeto
    - Indicador de Z actual durante autofoco
    """
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self.current_frame = None
        self.saliency_map = None
        self.detected_objects = []
        self.current_z = 0.0
        self.current_score = 0.0
        self.show_saliency = True
        self.show_boxes = True
        self.show_scores = True
    
    def update_frame(self, frame: np.ndarray):
        """Actualiza frame base."""
        self.current_frame = frame
        self.update()
    
    def update_detection(self, saliency: np.ndarray, objects: list):
        """Actualiza resultados de detecciÃ³n."""
        self.saliency_map = saliency
        self.detected_objects = objects
        self.update()
    
    def update_autofocus_state(self, z: float, score: float, active_obj_idx: int = -1):
        """Actualiza estado de autofoco."""
        self.current_z = z
        self.current_score = score
        self.active_object = active_obj_idx
        self.update()
    
    def paintEvent(self, event):
        """Renderiza frame con overlays."""
        if self.current_frame is None:
            return
        
        painter = QPainter(self)
        
        # 1. Dibujar frame base
        self._draw_frame(painter)
        
        # 2. Overlay de saliencia (si habilitado)
        if self.show_saliency and self.saliency_map is not None:
            self._draw_saliency_overlay(painter)
        
        # 3. Bounding boxes
        if self.show_boxes:
            self._draw_bounding_boxes(painter)
        
        # 4. Scores
        if self.show_scores:
            self._draw_scores(painter)
        
        # 5. Indicador de autofoco
        if self.active_object >= 0:
            self._draw_autofocus_indicator(painter)
```

**Tareas:**
- [ ] Crear `saliency_overlay.py`
- [ ] Implementar renderizado eficiente
- [ ] Controles de visibilidad (checkboxes)
- [ ] Colores configurables

---

### FASE 5: Refactorizar CameraTab

**Cambios en:** `src/gui/tabs/camera_tab.py`

```python
class CameraTab(QWidget):
    """
    PestaÃ±a de cÃ¡mara SIMPLIFICADA.
    
    Responsabilidades:
    - ConexiÃ³n/desconexiÃ³n de cÃ¡mara
    - Vista en vivo
    - Captura manual
    - ConfiguraciÃ³n de exposiciÃ³n/FPS
    
    NO incluye:
    - Controles de autofoco (movidos a AutofocusPanel)
    - LÃ³gica de microscopÃ­a (movida a MicroscopyService)
    """
    
    # SeÃ±ales (comunicaciÃ³n con servicios)
    frame_captured = pyqtSignal(np.ndarray)
    camera_connected = pyqtSignal(bool, str)
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self._setup_ui()
    
    def _setup_ui(self):
        """UI simplificada: solo controles de cÃ¡mara."""
        layout = QVBoxLayout(self)
        
        # Grupo 1: ConexiÃ³n
        # Grupo 2: Vista en vivo
        # Grupo 3: Captura manual
        # Grupo 4: ConfiguraciÃ³n
        
        # SIN: Controles de autofoco, microscopÃ­a, C-Focus
```

**Tareas:**
- [ ] Mover controles de autofoco a panel separado
- [ ] Eliminar dependencias a `parent_gui`
- [ ] Usar solo seÃ±ales para comunicaciÃ³n
- [ ] Reducir a ~400 lÃ­neas

---

### FASE 6: Panel de Autofoco Independiente

**Archivo:** `src/gui/panels/autofocus_panel.py` (NUEVO)

```python
class AutofocusPanel(QWidget):
    """
    Panel de controles de autofoco.
    
    Puede integrarse en CameraTab o como widget flotante.
    """
    
    # SeÃ±ales
    cfocus_connect_requested = pyqtSignal()
    cfocus_disconnect_requested = pyqtSignal()
    autofocus_start_requested = pyqtSignal(dict)  # config
    autofocus_stop_requested = pyqtSignal()
    params_changed = pyqtSignal(dict)
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self._setup_ui()
    
    def _setup_ui(self):
        layout = QVBoxLayout(self)
        
        # ConexiÃ³n C-Focus
        self._create_connection_group()
        
        # Modo de escaneo
        self._create_scan_mode_group()
        
        # ParÃ¡metros de detecciÃ³n
        self._create_detection_params_group()
        
        # ParÃ¡metros de Z
        self._create_z_params_group()
        
        # Estado y progreso
        self._create_status_group()
    
    def update_status(self, connected: bool, z_position: float = 0.0):
        """Actualiza indicadores de estado."""
        pass
    
    def update_progress(self, current: int, total: int, score: float):
        """Actualiza barra de progreso durante autofoco."""
        pass
```

**Tareas:**
- [ ] Crear `autofocus_panel.py`
- [ ] Mover todos los controles de autofoco
- [ ] Agregar barra de progreso
- [ ] Agregar grÃ¡fica Z vs Score

---

## ğŸ“Š Flujo de Datos Propuesto

### DetecciÃ³n en Tiempo Real

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CameraWorkerâ”‚â”€â”€â”€â”€â–¶â”‚DetectionWorkerâ”‚â”€â”€â”€â”€â–¶â”‚SaliencyOverlay  â”‚
â”‚ (30 FPS)    â”‚     â”‚ (U2-Net)     â”‚     â”‚ (Renderizado)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                    â”‚                     â”‚
      â”‚ frame_ready        â”‚ detection_complete  â”‚ paintEvent
      â”‚                    â”‚                     â”‚
      â–¼                    â–¼                     â–¼
   [Frame]           [Saliency, Objects]    [Frame + Overlays]
```

### Autofoco por Objeto

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User clicks â”‚â”€â”€â”€â”€â–¶â”‚AutofocusWorker â”‚â”€â”€â”€â”€â–¶â”‚ SaliencyOverlay â”‚
â”‚ "Start AF"  â”‚     â”‚ (Z-scanning)   â”‚     â”‚ (Progreso)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ z_position_changed
                           â”‚ scan_progress
                           â”‚ focus_found
                           â–¼
                    [Z, Score, Frame]
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ CaptureService  â”‚
                    â”‚ (Guardar imagen)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—“ï¸ Cronograma de ImplementaciÃ³n

### Sprint 1: Fundamentos (2-3 horas) âœ… COMPLETADO
- [x] **1.1** Crear `U2NetDetector` con carga real de modelo
- [x] **1.2** Descargar y verificar pesos `u2netp.pth`
- [x] **1.3** Test de detecciÃ³n con imagen estÃ¡tica

### Sprint 2: Servicios AsÃ­ncronos (3-4 horas) âœ… COMPLETADO
- [x] **2.1** Crear `DetectionService` con cola de frames
- [x] **2.2** Crear `AutofocusService` con seÃ±ales de progreso
- [x] **2.3** Integrar con `CFocusController`

### Sprint 3: VisualizaciÃ³n (2-3 horas) âœ… COMPLETADO
- [x] **3.1** Crear `SaliencyOverlayWidget`
- [x] **3.2** Implementar renderizado de mapas de probabilidad
- [x] **3.3** Agregar indicadores de score y Z

### Sprint 4: IntegraciÃ³n UI (2-3 horas) âœ… COMPLETADO
- [x] **4.1** Crear estructura de archivos
- [x] **4.2** Integrar servicios en main.py
- [x] **4.3** Conectar seÃ±ales y callbacks

### Sprint 5: Testing Final (1-2 horas) ğŸ”„ EN PROGRESO
- [ ] **5.1** Verificar carga de U2-Net al inicio
- [ ] **5.2** Probar detecciÃ³n en tiempo real
- [ ] **5.3** Probar autofoco con C-Focus

**Total estimado:** 11-16 horas

---

## âœ… Criterios de AceptaciÃ³n

### Funcionales
- [ ] U2-Net carga una sola vez al inicio de la aplicaciÃ³n
- [ ] DetecciÃ³n de objetos en tiempo real (>10 FPS)
- [ ] Mapa de saliencia visible como overlay
- [ ] Scores de objetos visibles en pantalla
- [ ] Z-scanning no bloquea la UI
- [ ] Progreso de autofoco visible durante escaneo
- [ ] ImÃ¡genes guardadas con enfoque Ã³ptimo

### No Funcionales
- [ ] Tiempo de carga de U2-Net < 5 segundos
- [ ] Latencia de detecciÃ³n < 100ms por frame
- [ ] Uso de memoria < 2GB adicionales
- [ ] UI responsive durante todo el proceso

---

## ğŸ“ Notas de ImplementaciÃ³n

### Dependencias Requeridas
```
torch>=1.9.0
torchvision>=0.10.0
opencv-python>=4.5.0
numpy>=1.20.0
PyQt5>=5.15.0
```

### Estructura de Archivos Final
```
src/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ detection/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ u2net_detector.py      # NUEVO
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ detection_service.py   # NUEVO
â”‚   â”‚   â”œâ”€â”€ autofocus_service.py   # NUEVO
â”‚   â”‚   â””â”€â”€ capture_service.py     # NUEVO
â”‚   â””â”€â”€ autofocus/
â”‚       â”œâ”€â”€ smart_focus_scorer.py  # REFACTORIZAR
â”‚       â””â”€â”€ multi_object_autofocus.py  # DEPRECAR
â”œâ”€â”€ gui/
â”‚   â”œâ”€â”€ tabs/
â”‚   â”‚   â””â”€â”€ camera_tab.py          # SIMPLIFICAR
â”‚   â”œâ”€â”€ panels/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ autofocus_panel.py     # NUEVO
â”‚   â””â”€â”€ widgets/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ saliency_overlay.py    # NUEVO
â””â”€â”€ models/
    â””â”€â”€ u2net/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ model_def.py           # EXISTENTE
        â””â”€â”€ u2netp.pth             # DESCARGAR
```

---

## ğŸ”„ Registro de Cambios

| Fecha | VersiÃ³n | Cambios |
|-------|---------|---------|
| 2025-12-12 | 1.0 | Documento inicial creado |
| 2025-12-12 | 2.0 | **IMPLEMENTACIÃ“N COMPLETADA** - Sprints 1-4 |
| 2025-12-12 | 2.1 | **LIMPIEZA DE CÃ“DIGO** - Eliminado cÃ³digo redundante |
| 2025-12-12 | 2.2 | **OVERLAY EN VENTANA DE CÃMARA** - DetecciÃ³n integrada |
| 2025-12-12 | 2.3 | **DETECCIÃ“N EN HILO SEPARADO** - No bloquea UI |
| 2025-12-12 | 2.4 | **OPTIMIZACIÃ“N GPU** - Preprocesamiento en GPU + logs detallados |
| 2025-12-12 | 2.5 | **DETECCIÃ“N PERIÃ“DICA** - Timer cada N segundos, no continua |
| 2025-12-12 | 2.6 | **FIX CONGELAMIENTO** - Cache de colormap, no resize en cada frame |
| 2025-12-12 | 2.7 | **MEJORA LOGS** - Logs detallados + mÃ©todo _update_colormap_cache |
| 2025-12-12 | 2.8 | **PARÃMETROS EDITABLES** - min_area, max_area, threshold en ventana cÃ¡mara |

---

## ğŸ§¹ Limpieza de CÃ³digo (v2.1)

### Cambios en `main.py`
- **LÃ­neas:** 935 â†’ 909 (-26 lÃ­neas)
- **Eliminado:** Variable `autofocus_controller` (redundante)
- **Simplificado:** `initialize_autofocus()` ahora usa `AutofocusService`
- **Refactorizado:** `_microscopy_capture_with_autofocus()` usa `U2NetDetector` singleton
- **Agregado:** `_advance_microscopy_point()` para cÃ³digo mÃ¡s limpio

### Cambios en `camera_tab.py`
- **Actualizado:** `_test_detection()` usa `U2NetDetector` singleton
- **Agregado:** `_create_detection_visualization()` para visualizaciÃ³n con saliencia
- **Eliminado:** Dependencia de `SmartFocusScorer` duplicado

### CÃ³digo Eliminado
- `SmartFocusScorer` ya no se instancia en `initialize_autofocus()`
- `MultiObjectAutofocusController` reemplazado por `AutofocusService`
- Variable `self.autofocus_controller` eliminada

---

## ğŸ¥ Overlay en Ventana de CÃ¡mara (v2.2)

### Cambios en `camera_window.py`
- **Checkbox** "ğŸ” Mostrar DetecciÃ³n U2-Net" para activar/desactivar overlay
- **Checkbox** "Saliencia" para mostrar/ocultar mapa de calor
- **Info label** muestra: objetos detectados, tiempo de inferencia, parÃ¡metros de Ã¡rea
- **MÃ©todos nuevos:**
  - `set_detector()` - Configura el detector U2-Net singleton
  - `set_detection_params()` - Actualiza Ã¡rea min/max en tiempo real
  - `_apply_detection_overlay()` - Aplica detecciÃ³n y dibuja overlay
  - `_create_overlay()` - Dibuja saliencia + bounding boxes + labels

### Cambios en `camera_tab.py`
- **`open_camera_view()`** - Configura detector U2-Net al abrir ventana
- **`_update_detection_params()`** - Sincroniza spinboxes con ventana
- **`on_camera_frame()`** - Pasa frame raw para detecciÃ³n
- **`_test_detection()`** - Ahora hace toggle del checkbox en ventana existente
- **Spinboxes** conectados a `_update_detection_params()` para actualizaciÃ³n en tiempo real

### Flujo de Uso
1. Conectar cÃ¡mara
2. Abrir ventana de cÃ¡mara (botÃ³n "Ver")
3. Iniciar vista en vivo
4. Activar checkbox "ğŸ” Mostrar DetecciÃ³n U2-Net"
5. Ajustar parÃ¡metros de Ã¡rea en la pestaÃ±a ImgRec
6. La imagen GUARDADA siempre es la ORIGINAL (sin overlays)

---

## ğŸ§µ DetecciÃ³n en Hilo Separado (v2.3)

### Problema Resuelto
- **Antes:** DetecciÃ³n bloqueaba UI (788ms de congelamiento)
- **Ahora:** DetecciÃ³n en `DetectionWorker` (QThread) - UI fluida

### Nuevos Componentes

#### `DetectionWorker` (QThread)
```python
class DetectionWorker(QThread):
    detection_done = pyqtSignal(object, list, float)  # saliency, objects, time_ms
    
    def detect_frame(self, frame):
        """Encola frame para detecciÃ³n (no bloquea)."""
        
    def run(self):
        """Ejecuta detecciÃ³n en hilo separado."""
```

### Cambios en `CameraViewWindow`
- **Checkbox "ğŸ” DetecciÃ³n Continua"** - Activa detecciÃ³n automÃ¡tica
- **Checkbox "Overlay"** - Muestra/oculta bounding boxes
- **Checkbox "Saliencia"** - Muestra/oculta mapa de calor
- **Info label** - Muestra: objetos, tiempo, FPS equivalente

### Flujo de DetecciÃ³n Continua
1. Usuario activa "DetecciÃ³n Continua"
2. Cada frame se envÃ­a al `DetectionWorker` (si no estÃ¡ ocupado)
3. Worker ejecuta U2-Net en hilo separado
4. Resultados se emiten via `detection_done` signal
5. UI actualiza overlay con Ãºltimos resultados
6. Frame rate de detecciÃ³n = 1000ms / tiempo_inferencia

### ParÃ¡metros de Ãrea (Corregidos)
- **Ãrea mÃ­nima:** 1000 px (antes 100 - detectaba ruido)
- **Ãrea mÃ¡xima:** 500000 px (antes 50000 - muy restrictivo)

---

## ğŸš€ OptimizaciÃ³n GPU (v2.4)

### Problema Identificado
- **300-600ms por detecciÃ³n** - Cuello de botella en preprocesamiento CPU
- **0 objetos detectados** - Umbral de saliencia muy alto (0.5)

### Optimizaciones Implementadas

#### 1. Preprocesamiento en GPU (`_preprocess_gpu`)
```python
# ANTES (CPU - lento):
image = cv2.resize(image, (320, 320))  # CPU
tensor = torch.from_numpy(image).to(device)  # CPU â†’ GPU

# AHORA (GPU - rÃ¡pido):
tensor = torch.from_numpy(image).to(device)  # CPU â†’ GPU inmediato
tensor = F.interpolate(tensor, size=(320, 320))  # Resize en GPU
```

#### 2. Resize de salida en GPU
```python
# ANTES:
saliency = d0.squeeze().cpu().numpy()
saliency = cv2.resize(saliency, (w_orig, h_orig))  # CPU

# AHORA:
saliency_gpu = F.interpolate(saliency_gpu, size=(h_orig, w_orig))  # GPU
saliency = saliency_gpu.squeeze().cpu().numpy()  # Solo transferencia
```

#### 3. Logs Detallados de Tiempos
```
[U2Net] Total=XXms | Preproc=XXms | Infer=XXms | Resize=XXms | Extract=XXms | Objetos=N
```

### ParÃ¡metros Ajustados
| ParÃ¡metro | Antes | Ahora | RazÃ³n |
|-----------|-------|-------|-------|
| `saliency_threshold` | 0.5 | 0.3 | MÃ¡s sensible a objetos |
| `min_area` | 100 | 500 | Evitar ruido |
| `max_area` | 50000 | 500000 | Detectar cÃ©lulas grandes |

### Rendimiento Esperado
- **Preprocesamiento:** ~5-10ms (antes ~50-100ms)
- **Inferencia:** ~20-30ms (sin cambio - ya era GPU)
- **Resize:** ~5ms (antes ~20ms)
- **Total:** ~50-80ms (antes 300-600ms)

---

## â±ï¸ DetecciÃ³n PeriÃ³dica (v2.5)

### Problema Identificado
La detecciÃ³n continua (cada frame) es innecesaria y consume recursos:
- U2-Net toma ~300-500ms por frame
- 30 FPS de cÃ¡mara = 30 detecciones/segundo imposible
- Solo necesitamos detectar cuando hay un trigger (trayectoria)

### SoluciÃ³n: DetecciÃ³n PeriÃ³dica con QTimer

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARQUITECTURA v2.5                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  CÃMARA (30 FPS)          DETECCIÃ“N (cada N seg)        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Frame 1      â”‚         â”‚                  â”‚          â”‚
â”‚  â”‚ Frame 2      â”‚         â”‚  QTimer (2s)     â”‚          â”‚
â”‚  â”‚ Frame 3      â”‚ â”€â”€â”€â”€â”€â”€â”€â–¶â”‚       â†“          â”‚          â”‚
â”‚  â”‚ ...          â”‚         â”‚  DetectionWorker â”‚          â”‚
â”‚  â”‚ Frame 60     â”‚         â”‚       â†“          â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  Saliency Map    â”‚          â”‚
â”‚         â†“                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚                    â”‚
â”‚  â”‚ video_label  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚  â”‚ + overlay    â”‚   (overlay persiste)                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Controles de UI
| Control | FunciÃ³n |
|---------|---------|
| **"ğŸ” Auto-Detectar"** | Activa/desactiva detecciÃ³n periÃ³dica |
| **"cada Xs"** | Intervalo de detecciÃ³n (1-10 segundos) |
| **"Saliencia"** | Muestra/oculta mapa de calor |
| **"Boxes"** | Muestra/oculta bounding boxes |

### Flujo de Datos
1. **CÃ¡mara** emite frames a 30 FPS
2. **update_frame()** muestra frame + overlay (si existe)
3. **QTimer** dispara cada N segundos
4. **DetectionWorker** ejecuta U2-Net en hilo separado
5. **Saliency map** se guarda y se superpone en frames siguientes

### Ventajas
- âœ… CÃ¡mara fluida a 30 FPS (sin bloqueos)
- âœ… DetecciÃ³n solo cuando es necesario
- âœ… Overlay persiste entre detecciones
- âœ… Intervalo configurable por usuario
- âœ… No consume GPU constantemente

---

## ğŸ› Fix Congelamiento (v2.6)

### Problema Identificado
El programa se congelaba al activar el overlay de saliencia.

**AnÃ¡lisis del log:**
```
13:39:37 | [U2Net] Total=534ms | Preproc=85ms | Infer=232ms | Resize=195ms | Extract=21ms
13:39:37 | DetecciÃ³n: 0 objetos en 535ms
13:39:40 | [U2Net] Total=555ms | ...
13:39:41 | DetecciÃ³n: 0 objetos en 557ms
13:39:43 | [U2Net] Total=454ms | ...
13:39:46 | DetecciÃ³n: 0 objetos en 455ms
(programa se congela - no mÃ¡s logs)
```

**Causa raÃ­z:**
El mÃ©todo `_draw_overlay()` se ejecutaba en **cada frame** (30 FPS) y hacÃ­a:
```python
# ANTES - Ejecutado 30 veces/segundo:
sal = cv2.resize(self.saliency_map, (1920, 1200))  # ~50ms
sal_color = cv2.applyColorMap(...)                  # ~20ms
vis = cv2.addWeighted(...)                          # ~10ms
# Total: ~80ms Ã— 30 = 2400ms/segundo (imposible)
```

### SoluciÃ³n: Cache de Colormap

**Arquitectura corregida:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 FLUJO OPTIMIZADO v2.6                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  DETECCIÃ“N (cada 2s)           VISUALIZACIÃ“N (30 FPS)   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ U2-Net detect()  â”‚          â”‚ update_frame()   â”‚     â”‚
â”‚  â”‚       â†“          â”‚          â”‚       â†“          â”‚     â”‚
â”‚  â”‚ saliency_map     â”‚          â”‚ raw_frame        â”‚     â”‚
â”‚  â”‚       â†“          â”‚          â”‚       +          â”‚     â”‚
â”‚  â”‚ cv2.resize()     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ saliency_colormapâ”‚     â”‚
â”‚  â”‚       â†“          â”‚  (cache) â”‚       â†“          â”‚     â”‚
â”‚  â”‚ cv2.applyColorMapâ”‚          â”‚ cv2.addWeighted()â”‚     â”‚
â”‚  â”‚       â†“          â”‚          â”‚   (solo blend)   â”‚     â”‚
â”‚  â”‚ saliency_colormapâ”‚          â”‚       â†“          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚ video_label      â”‚     â”‚
â”‚   (1 vez cada 2s)              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                 (30 veces/segundo)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CÃ³digo corregido:**
```python
# EN _on_detection_done() - Solo 1 vez por detecciÃ³n:
sal_resized = cv2.resize(saliency_map, (w, h))
self.saliency_colormap = cv2.applyColorMap(sal_resized, cv2.COLORMAP_JET)

# EN _draw_overlay() - 30 veces/segundo (rÃ¡pido):
vis = cv2.addWeighted(vis, 0.6, self.saliency_colormap, 0.4, 0)
```

### Variables de Cache Agregadas
```python
self.frame_size = None           # (w, h) del frame actual
self.saliency_colormap = None    # Cache del colormap pre-calculado
```

### Rendimiento
| OperaciÃ³n | Antes | Ahora |
|-----------|-------|-------|
| `cv2.resize()` | 30Ã—/s | 1Ã—/2s |
| `cv2.applyColorMap()` | 30Ã—/s | 1Ã—/2s |
| `cv2.addWeighted()` | 30Ã—/s | 30Ã—/s |
| **Tiempo por frame** | ~80ms | ~5ms |

---

## ğŸ“Š Mejora de Logs (v2.7)

### Problema
El log anterior no mostraba suficiente informaciÃ³n para diagnosticar problemas:
- No se sabÃ­a si el colormap se generaba correctamente
- No se sabÃ­a si el overlay se dibujaba

### Cambios Implementados

#### 1. Nuevo mÃ©todo `_update_colormap_cache()`
```python
def _update_colormap_cache(self):
    """Actualiza el cache del colormap cuando hay nuevo saliency_map."""
    if self.saliency_map is None or self.frame_size is None:
        self.saliency_colormap = None
        return
    
    w, h = self.frame_size
    sal_resized = cv2.resize(self.saliency_map, (w, h))
    self.saliency_colormap = cv2.applyColorMap(...)
    logger.debug(f"Colormap cache actualizado: {w}x{h}")
```

#### 2. Logs mejorados en `_on_detection_done()`
```python
has_colormap = "âœ“" if self.saliency_colormap is not None else "âœ—"
logger.info(f"DetecciÃ³n: {n_obj} objetos en {time_ms:.0f}ms, colormap={has_colormap}")
```

#### 3. Indicador visual en UI
```python
overlay_status = "ğŸŸ¢" if self.saliency_colormap is not None else "âšª"
self.frame_info.setText(f"Frame: {self.frame_count} | ... | Overlay: {overlay_status}")
```

### InterpretaciÃ³n de Logs
| Log | Significado |
|-----|-------------|
| `colormap=âœ“` | Colormap generado correctamente |
| `colormap=âœ—` | Error: frame_size es None (no hay frames) |
| `Overlay: ğŸŸ¢` | Overlay activo y listo para dibujar |
| `Overlay: âšª` | Sin overlay (no hay detecciÃ³n o error) |

---

## ğŸ›ï¸ ParÃ¡metros Editables (v2.8)

### Problema
Los parÃ¡metros de U2-Net estaban hardcodeados y no se podÃ­an modificar desde la UI:
- `min_area = 500` (fijo)
- `max_area = 500000` (fijo)
- `saliency_threshold = 0.3` (fijo)

Esto causaba que siempre se detectaran **0 objetos** porque los parÃ¡metros no eran adecuados para la imagen.

### SoluciÃ³n: Controles en Ventana de CÃ¡mara

Se agregaron spinboxes editables directamente en `CameraViewWindow`:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” Auto [2s] | Mapa â˜‘ | Boxes â˜‘ | Sin detecciÃ³n            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Ãrea: [100] - [500000] | Umbral: [0.30]                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚                    [VIDEO FEED]                             â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Controles Agregados
| Control | Rango | Default | DescripciÃ³n |
|---------|-------|---------|-------------|
| `min_area_spin` | 10-100000 | 100 | Ãrea mÃ­nima de objeto (px) |
| `max_area_spin` | 100-1000000 | 500000 | Ãrea mÃ¡xima de objeto (px) |
| `threshold_spin` | 0.05-0.95 | 0.30 | Umbral de saliencia |

### Flujo de ActualizaciÃ³n
```python
# Cuando el usuario cambia un parÃ¡metro:
_on_params_changed()
    â”œâ”€â”€ Actualiza self.detection_params
    â”œâ”€â”€ Actualiza DetectionWorker.set_params()
    â””â”€â”€ Actualiza U2NetDetector.set_parameters()
```

### GuÃ­a de Ajuste de ParÃ¡metros
| SituaciÃ³n | Ajuste |
|-----------|--------|
| No detecta objetos | Bajar `threshold` (ej: 0.1) |
| Detecta ruido/marcas pequeÃ±as | Subir `min_area` (ej: 1000) |
| No detecta objetos grandes | Subir `max_area` (ej: 800000) |
| Detecta demasiados objetos | Subir `threshold` (ej: 0.5) |

---

## ğŸ“ Archivos Creados/Modificados

### Nuevos MÃ³dulos
| Archivo | DescripciÃ³n | LÃ­neas |
|---------|-------------|--------|
| `src/core/detection/__init__.py` | Exports del mÃ³dulo | 9 |
| `src/core/detection/u2net_detector.py` | **Detector U2-Net Singleton** | ~320 |
| `src/core/services/__init__.py` | Exports de servicios | 9 |
| `src/core/services/detection_service.py` | **Servicio de detecciÃ³n asÃ­ncrono** | ~150 |
| `src/core/services/autofocus_service.py` | **Servicio de autofoco asÃ­ncrono** | ~230 |
| `src/gui/widgets/__init__.py` | Exports de widgets | 7 |
| `src/gui/widgets/saliency_overlay.py` | **Widget de visualizaciÃ³n con overlays** | ~300 |

### Archivos Modificados
| Archivo | Cambios |
|---------|---------|
| `src/main.py` | Imports de nuevos mÃ³dulos, inicializaciÃ³n de U2-Net al inicio, callbacks de servicios |

---

## âœ… Estado de VerificaciÃ³n

- [x] **U2-Net carga correctamente** - Verificado en CUDA
- [x] **Pesos u2netp.pth encontrados** - `models/weights/u2netp.pth`
- [x] **Imports funcionan** - Todos los mÃ³dulos importan sin errores
- [ ] **Test en tiempo real** - Pendiente prueba con cÃ¡mara
- [ ] **Test de autofoco** - Pendiente prueba con C-Focus

---

**Estado:** âœ… IMPLEMENTACIÃ“N BASE COMPLETADA - Listo para testing

---

## ğŸ”§ v3.0 - MISMO MÃ‰TODO QUE ImgAnalysisTab (2025-12-12)

### Problema Identificado
`U2NetDetector` **NO normaliza** la salida del modelo U2-Net:
```
[Extract] Saliency stats: min=0.000, max=0.037, mean=0.001, threshold=0.3
[Extract] Pixels above threshold: 0 (0.0%)
```
El mÃ¡ximo de saliencia es **0.037** pero el threshold es **0.3** â†’ **0 detecciones**.

`SmartFocusScorer` (vÃ­a `SalientObjectDetector`) **SÃ normaliza** a [0,1] â†’ funciona correctamente.

### SoluciÃ³n: MISMO MÃ‰TODO que ImgAnalysisTab

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        main.py                                   â”‚
â”‚  self.smart_focus_scorer = self.img_analysis_tab.scorer         â”‚
â”‚                            â”‚                                     â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚              â–¼                           â–¼                      â”‚
â”‚     ImgAnalysisTab                CameraViewWindow              â”‚
â”‚     (archivos)                   (cÃ¡mara en vivo)               â”‚
â”‚              â”‚                           â”‚                      â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                          â–¼                                      â”‚
â”‚                  SmartFocusScorer                               â”‚
â”‚                  (MISMO para ambos)                             â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚               SalientObjectDetector                             â”‚
â”‚               (normaliza salida a [0,1])                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cambios en camera_window.py

**DetectionWorker** usa `SmartFocusScorer` IGUAL que ImgAnalysisTab:
```python
def run(self):
    # PASO 1: Convertir a grayscale uint8 (IGUAL que ImgAnalysisTab)
    frame = self.frame
    if frame.dtype == np.uint16:
        frame = (frame / 256).astype(np.uint8)
    if len(frame.shape) == 3:
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # PASO 2: Usar scorer.assess_image() IGUAL que ImgAnalysisTab
    result = self.scorer.assess_image(frame)
    
    # PASO 3: Extraer probability_map y objects
    probability_map = result.probability_map  # Ya normalizado [0,1]
    objects = result.objects  # Lista de ObjectInfo
```

**Objetos detectados** usan `ObjectInfo` de SmartFocusScorer:
```python
# ObjectInfo attributes:
# - bounding_box: (x, y, w, h)
# - centroid: (cx, cy)
# - focus_score: float
# - is_focused: bool
# - area: float
```

### Flujo de Datos (IGUAL que ImgAnalysisTab)
```
CameraTab.open_camera_view()
    â”‚
    â””â”€â”€ camera_view_window.set_scorer(parent_gui.smart_focus_scorer)

Cada N segundos:
    â”‚
    â””â”€â”€ detection_worker.detect_frame(raw_frame)
            â”‚
            â”œâ”€â”€ Convertir uint16 â†’ uint8 grayscale
            â”‚
            â””â”€â”€ scorer.assess_image(frame)  â† MISMO MÃ‰TODO
                    â”‚
                    â””â”€â”€ Emite: (probability_map, objects, time_ms)
```

### Fix CrÃ­tico: ConversiÃ³n de Frame
La cÃ¡mara Thorlabs envÃ­a `uint16`. ImgAnalysisTab usa `cv2.IMREAD_GRAYSCALE` (uint8).
```python
if frame.dtype == np.uint16:
    frame = (frame / 256).astype(np.uint8)
if len(frame.shape) == 3:
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
```

---

## ğŸ“Š Resumen de Arquitectura Final

### Componente Ãšnico de DetecciÃ³n
| Componente | Archivo | Uso |
|------------|---------|-----|
| `SmartFocusScorer` | `img_analysis/smart_focus_scorer.py` | **AMBOS** (ImgAnalysisTab y CameraViewWindow) |

### ParÃ¡metros de SmartFocusScorer
| ParÃ¡metro | Default | DescripciÃ³n |
|-----------|---------|-------------|
| `threshold` | 0.5 | Umbral de saliencia normalizado |
| `min_area` | 500 | Ãrea mÃ­nima de objeto (px) |
| `min_prob` | 0.3 | Probabilidad mÃ­nima |

---

**Estado:** âœ… v3.0 IMPLEMENTADA - MISMO mÃ©todo que ImgAnalysisTab

---

## ğŸ”§ v3.1 - CORRECCIONES (2025-12-12)

### Errores Corregidos

1. **`_run_detection` no existe** â†’ Cambiado a `_trigger_detection`
   - `camera_tab.py` lÃ­nea 1208: `self.camera_view_window._trigger_detection()`

2. **Signal con frame para overlay consistente**
   - `DetectionWorker.detection_done` ahora emite: `(probability_map, objects, time_ms, frame_used)`
   - Permite guardar el frame que se usÃ³ para detecciÃ³n

3. **Colormap usa tamaÃ±o del frame EN VIVO**
   - `_update_colormap_cache()` ahora usa `last_raw_frame.shape` (1920x1200)
   - Garantiza que el overlay coincida con el video en vivo

### Flujo Corregido
```
DetectionWorker.run()
    â”‚
    â”œâ”€â”€ Convierte frame a uint8 grayscale
    â”‚
    â”œâ”€â”€ scorer.assess_image(frame)
    â”‚
    â””â”€â”€ Emite: (probability_map, objects, time_ms, frame_usado)
            â”‚
            â””â”€â”€ _on_detection_done()
                    â”‚
                    â”œâ”€â”€ Guarda detection_frame
                    â”‚
                    â””â”€â”€ _update_colormap_cache()
                            â”‚
                            â””â”€â”€ Usa last_raw_frame.shape (1920x1200)
```

**Estado:** âœ… v3.1 - Errores corregidos

---

## ğŸ”§ v3.2 - FIX OVERLAY NEGRO (2025-12-12)

### Problema
La imagen quedaba en NEGRO cuando se activaba el overlay. Solo se veÃ­an los bounding boxes sobre fondo negro.

### Causa
El mÃ©todo `_draw_overlay` usaba un sistema de cache de colormap que fallaba cuando los tamaÃ±os no coincidÃ­an.

### SoluciÃ³n
Reescribir `_draw_overlay` para que sea IDÃ‰NTICO a `ImgAnalysisTab._refresh_view()`:

```python
def _draw_overlay(self, frame):
    # PASO 1: Convertir a uint8 BGR
    if frame.dtype == np.uint16:
        frame_uint8 = (frame / 256).astype(np.uint8)
    
    if len(frame_uint8.shape) == 2:
        vis = cv2.cvtColor(frame_uint8, cv2.COLOR_GRAY2BGR)
    
    # PASO 2: Overlay de probabilidad (resize al tamaÃ±o del frame actual)
    if self.saliency_map is not None:
        prob_resized = cv2.resize(self.saliency_map, (w, h))
        prob_uint8 = (prob_resized * 255).astype(np.uint8)
        heatmap = cv2.applyColorMap(prob_uint8, cv2.COLORMAP_JET)
        vis = cv2.addWeighted(vis, 0.5, heatmap, 0.5, 0)
    
    # PASO 3: Bounding boxes
    for obj in self.detected_objects:
        cv2.rectangle(vis, ...)
```

**Estado:** âœ… v3.2 - Overlay corregido
